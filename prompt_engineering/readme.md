# **a. Fundamentals**

### 1. What is Prompt Engineering?

- It is the **art and science of crafting instructions** for AI models (like ChatGPT) to produce desired outputs.
- In simple words, itâ€™s *how you ask* the AI to do something.
- **Goal:** â¡ï¸ To **tell the model how to behave and what to produce.**

**Why it matters:**

- You donâ€™t need to be a programmer.
- A well-written prompt gives much better and more accurate results.
- Itâ€™s an important skill for productivity and AI-related careers.

---

### ğŸ”¹ What is Context Engineering?

- It means **providing relevant facts, documents, or data** that the model uses to give correct and grounded answers.
- In simple words, itâ€™s *what you show* the AI to help it answer correctly.
- **Goal:** â¡ï¸ To **give the model the right information or facts** it should rely on when answering.

---

### ğŸ†š **Prompt vs. Context Engineering**

| Aspect | Prompt Engineering | Context Engineering |
| --- | --- | --- |
| **Goal** | How to guide the modelâ€™s behavior | What info the model should use |
| **Focus** | Wording, structure, examples | Documents, data, tools, memory |
| **Example** | â€œBe brief. Output JSON.â€ | â€œUse info from this PDF.â€ |
| **Common issue** | Unclear prompt â†’ bad output | Missing data â†’ hallucinations |
| **One-liner** | ğŸ—£ï¸ **How you ask** | ğŸ“„ **What you show** |

---

### âš™ï¸ **How They Work Together**

1. **Start with a good prompt** â†’ The **prompt guides** the modelâ€™s behavior.
2. **Add grounding context** â†’ The **context supplies** the knowledge.

â¡ï¸ You usually need both together for best results.

---

## **2. Understanding Large Language Models (LLMs)**

### ğŸ”¹ What Are LLMs?

- LLMs are **prediction engines** that:
    1. Take your text input (prompt).
    2. Predict the **next most likely word or token**.
    3. Continue predicting to form a complete response.
- They learn patterns from **large datasets** during training.

---

### **3. Common Failure Modes**

1. **Hallucinations:**
    - When the model creates false or imaginary information due to missing or irrelevant context.
2. **Messy Outputs:**
    - Caused by vague or unclear prompts.
3. **Outdated or Inaccurate Info:**
    - When the model isnâ€™t properly grounded with fresh or correct data.

---

### **4. Recommended Workflows**

1. **Start with a clear prompt** (define the task, tone, and structure).
2. **Then ground it with context** (add documents, data, or tools).
3. **In agentic systems:**
    - Feed tool or API outputs back into context for the next step.
4. Always **iterate and test** prompts for best performance.

---

### 5. Key Concept â€” â€œSophisticated Autocompleteâ€

- LLMs donâ€™t **understand** like humans.
- They **predict** what should come next based on the given input.
- Thatâ€™s why **your prompt and context** matter so much â€” they set up the right â€œautocomplete environment.â€

---
